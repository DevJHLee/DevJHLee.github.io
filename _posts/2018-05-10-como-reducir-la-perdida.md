---
layout: post
title: Como reducir la perdida
category: Machine Learning
---

&iquest;C&oacute;mo se reduce la p&eacute;rdida?

La derivada de (y - y')2 con respecto a los pesos y sesgos nos indica c&oacute;mo cambia la p&eacute;rdida en un ejemplo determinado:

Es simple de computar y convexa.

Por lo tanto, tomamos pasos peque&ntilde;os reiteradamente en la direcci&oacute;n que minimiza la p&eacute;rdida:

Los llamamos pasos de gradiente (aunque en realidad son pasos de gradiente negativos).

Esta estrategia de optimizaci&oacute;n se denomina descenso de gradientes.

Ejercicios que te ayudaran a contextualizar mas la perdida y como reducirla [AQU&Iacute;](https://developers.google.com/machine-learning/crash-course/fitter/graph)